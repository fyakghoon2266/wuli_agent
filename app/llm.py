# app/llm.py
import os
from typing import List, Dict, Any
import json
import psycopg2 # æ–°å¢é€™å€‹
import datetime

from typing import Optional

import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart

from dotenv import load_dotenv
load_dotenv()

from langchain_core.messages import (
    SystemMessage,
    HumanMessage,
    AIMessage,
    BaseMessage,
)
from langchain_openai import ChatOpenAI, AzureChatOpenAI
from langchain_aws import ChatBedrock

# å¼•å…¥ Agent ç›¸é—œå¥—ä»¶
from langchain.tools import tool
# from langchain.agents import create_tool_calling_agenc
from langchain_classic.agents import AgentExecutor, create_tool_calling_agent
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from gradio_client import Client

from .rag.retriever import retrieve_cards, init_rag

# ===================== LLM Provider è¨­å®š =====================
# (ä¿ç•™ä½ åŸæœ¬çš„è¨­å®šé‚è¼¯ï¼Œå®Œå…¨ä¸å‹•)
LLM_PROVIDER = os.getenv("LLM_PROVIDER", "azure").lower()
TIMEOUT_SECONDS = 60

# --- OpenAI ---
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4.1-mini")

# --- Bedrock ---
BEDROCK_MODEL_ID = os.getenv(
    "BEDROCK_MODEL_ID",
    "anthropic.claude-3-5-sonnet-20241022-v2:0",
)
AWS_REGION = os.getenv("AWS_REGION", "us-west-2")

# --- Azure OpenAI ---
AZURE_OPENAI_ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT")
AZURE_OPENAI_API_KEY = os.getenv("AZURE_OPENAI_API_KEY")
AZURE_OPENAI_API_VERSION = os.getenv("AZURE_OPENAI_API_VERSION", "2024-05-01-preview")
AZURE_OPENAI_DEPLOYMENT = os.getenv("AZURE_OPENAI_DEPLOYMENT")

# è¨­å®šä½ çš„ Email è³‡è¨Š (å»ºè­°ä¹‹å¾Œæ”¹æ”¾åˆ° .env)
SMTP_SERVER = "smtp.gmail.com"
SMTP_PORT = 587
SENDER_EMAIL = os.getenv("SENDER_EMAIL")  # Wuli çš„ç™¼ä¿¡å¸³è™Ÿ
SENDER_PASSWORD = os.getenv("SENDER_PASSWORD") # æ‡‰ç”¨ç¨‹å¼å¯†ç¢¼
ENGINEER_EMAIL = os.getenv("ENGINEER_EMAIL") # å€¼ç­å·¥ç¨‹å¸«çš„ Email

LITELLM_DB_CONFIG = {
    "dbname": "litellm",
    "user": "postgres",
    "password": "sk-1234",
    "host": "localhost", 
    "port": "5432"
}


def build_llm():
    # (ä¿ç•™åŸæœ¬çš„ build_llm é‚è¼¯ï¼Œé€™è£¡çœç•¥ä»¥ç¯€çœç¯‡å¹…ï¼Œè«‹ç›´æ¥ç”¨ä½ åŸæœ¬çš„ç¨‹å¼ç¢¼)
    if LLM_PROVIDER == "azure":
        if not (AZURE_OPENAI_ENDPOINT and AZURE_OPENAI_API_KEY and AZURE_OPENAI_DEPLOYMENT):
             raise RuntimeError("LLM_PROVIDER=azureï¼Œä½† AZURE_OPENAI_* å°šæœªå®Œæ•´è¨­å®šã€‚")
        return AzureChatOpenAI(
            azure_endpoint=AZURE_OPENAI_ENDPOINT,
            api_key=AZURE_OPENAI_API_KEY,
            api_version=AZURE_OPENAI_API_VERSION,
            azure_deployment=AZURE_OPENAI_DEPLOYMENT,
            timeout=TIMEOUT_SECONDS,
            temperature=0.2,
            streaming=True # å»ºè­°é–‹å•Ÿ Streaming
        )

    if LLM_PROVIDER == "bedrock":
        return ChatBedrock(
            model_id=BEDROCK_MODEL_ID,
            region_name=AWS_REGION,
            timeout=TIMEOUT_SECONDS,
            temperature=0.2,
            streaming=True # å»ºè­°é–‹å•Ÿ Streaming
        )

    # é è¨­ OpenAI
    if not OPENAI_API_KEY:
        raise RuntimeError("LLM_PROVIDER=openaiï¼Œä½† OPENAI_API_KEY æœªè¨­å®šã€‚")

    return ChatOpenAI(
        api_key=OPENAI_API_KEY,
        model=OPENAI_MODEL,
        timeout=TIMEOUT_SECONDS,
        temperature=0.2,
        streaming=True # å»ºè­°é–‹å•Ÿ Streaming
    )


LLM = build_llm()

# å•Ÿå‹•æ™‚å…ˆæŠŠ error_docs å»ºé€² Chroma
ERROR_CARDS, ERROR_COLLECTION = init_rag()


# ===================== å®šç¾© Tools (å·¥å…·) =====================

@tool
def search_error_cards(query: str):
    """
    é€™æ˜¯ä¸€å€‹ã€Œç¶­é‹æ‰‹å†Š/éŒ¯èª¤å¡ç‰‡æœå°‹å·¥å…·ã€ã€‚
    ç•¶ä½¿ç”¨è€…è©¢å•é—œæ–¼ç³»çµ±éŒ¯èª¤ä»£ç¢¼ (Error Code)ã€Log å…§å®¹ã€GAIA å¹³å°æ¶æ§‹ã€
    è­·æ¬„ (Guardrails)ã€Proxy è¨­å®šã€Token èªè­‰ã€504 Timeoutã€407 Error
    æˆ–ä»»ä½•ç³»çµ±ç•°å¸¸æ’æŸ¥æ™‚ï¼Œ**å¿…é ˆ**ä½¿ç”¨æ­¤å·¥å…·ä¾†æŸ¥è©¢å…§éƒ¨æ–‡ä»¶ã€‚
    
    è¼¸å…¥ query æ‡‰è©²æ˜¯ä½¿ç”¨è€…é‡åˆ°çš„éŒ¯èª¤è¨Šæ¯æˆ–å•é¡Œé—œéµå­—ã€‚
    """
    # é€™è£¡ç›´æ¥å‘¼å«ä½ åŸæœ¬çš„ retrieve_cards
    hits = retrieve_cards(query, k=3)
    
    if not hits:
        return "æœå°‹ç¶­é‹æ‰‹å†Šå¾Œï¼Œæ²’æœ‰ç™¼ç¾ç›´æ¥ç›¸é—œçš„èªªæ˜ã€‚"

    context_blocks = []
    for idx, (card_id, content) in enumerate(hits, start=1):
        context_blocks.append(f"[Result {idx}: {card_id}]\n{content}")
    
    return "\n\n".join(context_blocks)

@tool
def send_email_to_engineer(user_name: str, user_email: str, problem_summary: str, attempted_steps: str):
    """
    ã€å¯„ä¿¡çµ¦å€¼ç­å·¥ç¨‹å¸«å·¥å…·ã€‘
    
    ä½¿ç”¨æ™‚æ©Ÿï¼š
    1. ç•¶ä½¿ç”¨è€…è¦æ±‚äººå·¥ä»‹å…¥ã€‚
    2. å¿…é ˆè¦æ±‚ä½¿ç”¨è€…æä¾›ã€ŒEmail ä¿¡ç®±ã€ï¼Œå› ç‚ºæœƒå¯„é€å‰¯æœ¬çµ¦ä½¿ç”¨è€…ç•™å­˜ã€‚
    
    Args:
        user_name: ä½¿ç”¨è€…çš„ç¨±å‘¼ (ä¾‹å¦‚ï¼šå°é™³ã€Jason)ã€‚
        user_email: ä½¿ç”¨è€…çš„ Email ä¿¡ç®± (å¿…é ˆæ˜¯åˆæ³•çš„ Email æ ¼å¼ï¼Œç”¨æ–¼å¯„é€å‰¯æœ¬)ã€‚
        problem_summary: å•é¡Œçš„è©³ç´°æ‘˜è¦ (åŒ…å«éŒ¯èª¤ç¢¼ã€ç™¼ç”Ÿæ™‚é–“ã€ç¾è±¡)ã€‚
        attempted_steps: ä½¿ç”¨è€…å·²ç¶“å˜—è©¦éå“ªäº›æ’æŸ¥æ­¥é©Ÿã€‚
    """
    try:
        # ç°¡å–®é©—è­‰ Email æ ¼å¼ (é˜²å‘†)
        if "@" not in user_email or "." not in user_email:
            return f"âŒ å¯„ä¿¡å¤±æ•—ï¼šæä¾›çš„è¯çµ¡è³‡è¨Š '{user_email}' çœ‹èµ·ä¾†ä¸åƒæœ‰æ•ˆçš„ Email æ ¼å¼ã€‚è«‹è¦æ±‚ä½¿ç”¨è€…æä¾›æ­£ç¢ºçš„ä¿¡ç®±ä»¥ä¾¿å¯„é€å‰¯æœ¬ã€‚"

        # å»ºç«‹éƒµä»¶å…§å®¹
        msg = MIMEMultipart()
        msg['From'] = SENDER_EMAIL
        msg['To'] = ENGINEER_EMAIL
        msg['Cc'] = user_email  # <--- é—œéµä¿®æ”¹ï¼šè¨­å®šå‰¯æœ¬çµ¦ä½¿ç”¨è€…
        msg['Subject'] = f"ã€Wuli Agent æ±‚åŠ©ã€‘ä½¿ç”¨è€…ï¼š{user_name}"

        body = f"""
        å€¼ç­å·¥ç¨‹å¸«ä½ å¥½ï¼ŒWuli æ”¶åˆ°ä½¿ç”¨è€…çš„æ±‚åŠ©è«‹æ±‚ã€‚
        (æœ¬éƒµä»¶å·²è‡ªå‹•å‰¯æœ¬çµ¦ä½¿ç”¨è€… {user_name} ç•™å­˜)
        
        ================================================
        ğŸ‘¤ ä½¿ç”¨è€…èº«ä»½
        å§“åï¼š{user_name}
        è¯çµ¡ä¿¡ç®±ï¼š{user_email}
        
        ğŸ”´ é­é‡å•é¡Œæ‘˜è¦
        {problem_summary}
        
        ğŸ› ï¸ ä½¿ç”¨è€…å·²å˜—è©¦éçš„æ­¥é©Ÿ
        {attempted_steps}
        ================================================
        
        è«‹å”åŠ©ç¢ºèªï¼Œè¬è¬ï¼
        (æœ¬éƒµä»¶ç”± Wuli Agent è‡ªå‹•å½™æ•´ç™¼é€)
        """
        msg.attach(MIMEText(body, 'plain'))

        # é€£ç·š SMTP Server å¯„ä¿¡
        server = smtplib.SMTP(SMTP_SERVER, SMTP_PORT)
        server.starttls()
        server.login(SENDER_EMAIL, SENDER_PASSWORD)
        
        # æ³¨æ„ï¼šsend_message çš„æ”¶ä»¶äººæ¸…å–®å¿…é ˆåŒ…å« To å’Œ Cc çš„æ‰€æœ‰äºº
        recipients = [ENGINEER_EMAIL, user_email]
        server.send_message(msg, to_addrs=recipients)
        
        server.quit()
        
        return f"âœ… ä¿¡ä»¶å·²æˆåŠŸå¯„å‡ºï¼\næ”¶ä»¶äººï¼šå·¥ç¨‹å¸«\nå‰¯æœ¬(CC)ï¼š{user_name} ({user_email})\nè«‹ä½¿ç”¨è€…å»æ”¶ä¿¡ç¢ºèªå–”ï¼"
        
    except Exception as e:
        return f"âŒ å¯„ä¿¡å¤±æ•—ï¼š{str(e)}"

@tool
def search_litellm_logs(
    keyword: str = "",
    lookback_minutes: int = 60,
    start_time: Optional[str] = None,
    end_time: Optional[str] = None
):
    """
    ã€LiteLLM Log æŸ¥è©¢å·¥å…· - è‡ªå‹•æ ¡æ­£æ™‚å€ç‰ˆã€‘
    
    åŠŸèƒ½ï¼šæŸ¥è©¢ Log ä¸¦è‡ªå‹•å°‡ UTC æ™‚é–“è½‰æ›ç‚ºå°åŒ—æ™‚é–“ (+8) é¡¯ç¤ºã€‚
    """
    try:
        conn = psycopg2.connect(**LITELLM_DB_CONFIG)
        cursor = conn.cursor()

        # [é‡é» 1] åœ¨ SQL æŸ¥è©¢æ¬„ä½æ™‚ï¼Œç›´æ¥ +8 å°æ™‚ï¼Œè®“å›å‚³çµ¦ Python çš„å°±æ˜¯å°åŒ—æ™‚é–“
        base_sql = """
        SELECT 
            ("startTime" + INTERVAL '8 hours') as local_time,
            "user",
            messages, 
            proxy_server_request, 
            response
        FROM "LiteLLM_SpendLogs"
        """
        
        conditions = []
        params = []

        # --- å‹•æ…‹æ±ºå®šæŸ¥è©¢æ¢ä»¶ ---
        
        # é€™è£¡çš„é‚è¼¯æ˜¯ï¼š
        # è³‡æ–™åº«è£¡çš„ startTime æ˜¯ UTC (02:00)ã€‚
        # åŠ ä¸Š 8 å°æ™‚å¾Œè®Šæˆå°åŒ—æ™‚é–“ (10:00)ã€‚
        # æˆ‘å€‘æ‹¿é€™å€‹ã€Œè®Šæ›å¾Œçš„æ™‚é–“ã€ä¾†è·Ÿä½¿ç”¨è€…çš„æ¢ä»¶ (10:00) åšæ¯”è¼ƒã€‚

        if start_time:
            # çµ•å°æ™‚é–“æŸ¥è©¢
            conditions.append('("startTime" + INTERVAL \'8 hours\') >= %s')
            params.append(start_time)
            
            if end_time:
                conditions.append('("startTime" + INTERVAL \'8 hours\') <= %s')
                params.append(end_time)
                
        else:
            # ç›¸å°æ™‚é–“æŸ¥è©¢ (æœ€è¿‘ N åˆ†é˜)
            # å› ç‚ºä½ çš„ DB å·²ç¶“è¨­æˆ Asia/Taipeiï¼Œæ‰€ä»¥ NOW() æ˜¯å°åŒ—æ™‚é–“
            # æˆ‘å€‘æ‹¿ (UTCè³‡æ–™ + 8) ä¾†è·Ÿ (å°åŒ—NOW) æ¯”è¼ƒï¼Œé€™æ¨£å–®ä½å°±çµ±ä¸€äº†
            conditions.append('("startTime" + INTERVAL \'8 hours\') >= NOW() - INTERVAL %s') 
            params.append(f"{lookback_minutes} minutes")

        # çµ„åˆ WHERE å­å¥
        if conditions:
            base_sql += " WHERE " + " AND ".join(conditions)
        
        # æ’åº (ç”¨åŸå§‹ startTime æ’å°±å¥½ï¼Œçµæœä¸€æ¨£)
        base_sql += ' ORDER BY "startTime" DESC LIMIT 15;'

        # åŸ·è¡ŒæŸ¥è©¢
        cursor.execute(base_sql, tuple(params))
        rows = cursor.fetchall()
        
        if not rows:
            return f"ğŸ“­ æŸ¥è©¢å®Œæˆï¼Œä½†åœ¨æŒ‡å®šå€é–“å…§æ²’æœ‰æ‰¾åˆ° Log (å·²è‡ªå‹•æ ¡æ­£ +8 æ™‚å€)ã€‚"

        result_text = []
        for row in rows:
            t_start, user_id, msgs, proxy_req, resp = row
            
            # t_start ç¾åœ¨å·²ç¶“æ˜¯ Postgres ç®—å¥½çš„å°åŒ—æ™‚é–“äº†ï¼Œç›´æ¥è½‰å­—ä¸²
            # å¦‚æœå®ƒæ˜¯ datetime ç‰©ä»¶ï¼Œè½‰æˆä¹¾æ·¨çš„å­—ä¸²æ ¼å¼
            if isinstance(t_start, datetime.datetime):
                t_start_str = t_start.strftime("%Y-%m-%d %H:%M:%S")
            else:
                t_start_str = str(t_start)

            # --- è§£æ Prompt (Input) ---
            prompt_content = "(ç„¡æ³•è®€å– Prompt)"
            if isinstance(msgs, list) and len(msgs) > 0:
                prompt_content = msgs[-1].get('content', '')
            elif proxy_req:
                try:
                    hidden_msgs = proxy_req.get('messages') or proxy_req.get('body', {}).get('messages')
                    if hidden_msgs:
                        prompt_content = hidden_msgs[-1].get('content', '')
                except:
                    pass

            # é—œéµå­—éæ¿¾
            if keyword:
                search_target = f"{str(user_id)} {prompt_content}"
                if keyword.lower() not in search_target.lower():
                    continue

            # --- è§£æ Response (Output) ---
            output_content = "Success"
            if isinstance(resp, dict):
                if 'error' in resp:
                    output_content = f"âŒ Error: {resp['error']}"
                else:
                    choices = resp.get('choices', [])
                    if choices:
                        output_content = f"âœ… Reply: {choices[0]['message']['content'][:50]}..."

            # æ ¼å¼åŒ–è¼¸å‡º
            log_entry = (
                f"â° æ™‚é–“ (Taipei): {t_start_str}\n"
                f"ğŸ‘¤ User: {user_id}\n"
                f"ğŸ“ Prompt: {prompt_content[:200]}...\n"
                f"ğŸ“¤ ç‹€æ…‹: {output_content}\n"
                "------------------------------------------------"
            )
            result_text.append(log_entry)

        conn.close()
        
        if not result_text:
            return f"å·²æœå°‹è³‡æ–™åº«ï¼Œä½†åœ¨éæ¿¾é—œéµå­— '{keyword}' å¾Œæ²’æœ‰ç¬¦åˆçš„ç´€éŒ„ã€‚"
            
        return "\n".join(result_text)

    except Exception as e:
        return f"ğŸ’¥ è³‡æ–™åº«æŸ¥è©¢å¤±æ•—: {str(e)}"

from gradio_client import Client # <--- è¨˜å¾—åœ¨æœ€ä¸Šé¢åŠ é€™å€‹

# ... (å…¶ä»–çš„ import å’Œå·¥å…·) ...

@tool
def verify_prompt_with_guardrails(prompt_content: str):
    """
    ã€è­·æ¬„é˜»æ“‹åŸå› æª¢æŸ¥å™¨ã€‘
    
    ä½¿ç”¨æ™‚æ©Ÿï¼š
    1. ç•¶ `search_litellm_logs` æŸ¥åˆ°æŸå€‹ Prompt è¢«é˜»æ“‹ï¼Œä½† Log è£¡æ²’æœ‰è©³ç´°åŸå› æ™‚ã€‚
    2. ä½¿ç”¨è€…å•ï¼šã€Œç‚ºä»€éº¼é€™å¥è©±ä¸è¡Œï¼Ÿã€ã€ã€Œå¹«æˆ‘æª¢æŸ¥é€™å¥è©±æœ‰æ²’æœ‰é•è¦ã€ã€‚
    3. Wuli éœ€è¦åˆ¤æ–·æŸå€‹ Payload åˆ°åº•æ˜¯ä¸­äº†ã€Œé—œéµå­—ã€ã€ã€Œæ­£å‰‡ã€é‚„æ˜¯ã€ŒLLM å¯©æŸ¥ã€ã€‚
    4. ã€ç›´æ¥æª¢æŸ¥ã€‘ï¼šç•¶ä½¿ç”¨è€…ç›´æ¥è²¼å‡ºä¸€æ®µæ–‡å­—å•ï¼šã€Œé€™å¥è©±ç‚ºä»€éº¼è¢«æ“‹ï¼Ÿã€ã€ã€Œå¹«æˆ‘æª¢æŸ¥é€™æ®µ Prompt æœ‰æ²’æœ‰é•è¦ã€ã€ã€Œé€™å¥è©±æœƒéå—ï¼Ÿã€ã€‚
    
    Args:
        prompt_content: è¦æª¢æŸ¥çš„ä½¿ç”¨è€…è¼¸å…¥å…§å®¹ (User Prompt)ã€‚
    """
    try:
        # é€£ç·šåˆ°ä½ çš„ Guardrails API
        client = Client("https://35.78.175.148/guardrails/", ssl_verify=False)
        
        # å‘¼å«é æ¸¬
        result = client.predict(
            user_text=prompt_content,
            api_name="/check_all"
        )
        
        # result æ˜¯ä¸€å€‹ tupleï¼ŒåŒ…å« (LLMæª¢æŸ¥çµæœ, é—œéµå­—æª¢æŸ¥çµæœ, æ­£å‰‡æª¢æŸ¥çµæœ)
        # æˆ‘å€‘æŠŠå®ƒçµ„åˆæˆæ¸…æ¥šçš„å­—ä¸²å›å‚³çµ¦ Wuli
        formatted_result = (
            f"ğŸ›¡ï¸ ã€æª¢æŸ¥å ±å‘Šã€‘ é‡å°å…§å®¹: '{prompt_content[:50]}...'\n"
            f"1. {result[0]}\n"
            f"2. {result[1]}\n"
            f"3. {result[2]}\n"
        )
        return formatted_result

    except Exception as e:
        return f"ğŸ’¥ å‘¼å«è­·æ¬„ API å¤±æ•—: {str(e)}"

# æœªä¾†å¦‚æœæœ‰ LiteLLM DB å·¥å…·ï¼Œå°±åŠ åœ¨é€™è£¡
# @tool
# def check_litellm_logs(user_id: str): ...


# ===================== å»ºç«‹ Agent =====================

def build_agent_executor():
    # 1. å·¥å…·æ¸…å–®ï¼šåŠ å…¥ send_email_to_engineer
    tools = [
        search_error_cards, 
        send_email_to_engineer,
        search_litellm_logs, 
        verify_prompt_with_guardrails] 

    # 2. Agent Prompt (ä¿æŒä¸è®Š)
    prompt = ChatPromptTemplate.from_messages([
        ("system", "{system_message}"), 
        MessagesPlaceholder(variable_name="chat_history"),
        ("human", "{input}"),
        MessagesPlaceholder(variable_name="agent_scratchpad"),
    ])

    # 3. å»ºç«‹ Agent
    agent = create_tool_calling_agent(LLM, tools, prompt)

    # 4. å»ºç«‹ Executor
    return AgentExecutor(agent=agent, tools=tools, verbose=True)

# å»ºç«‹å…¨åŸŸçš„ Executor å¯¦é«”
AGENT_EXECUTOR = build_agent_executor()