# app/llm_factory.py

from langchain_openai import ChatOpenAI, AzureChatOpenAI
from langchain_aws import ChatBedrock
# æ³¨æ„ï¼šå¦‚æœä½ ä½¿ç”¨çš„æ˜¯æ–°ç‰ˆ langchainï¼Œå¯èƒ½éœ€è¦æ”¹ç‚º from langchain.agents import ...
from langchain_classic.agents import AgentExecutor, create_tool_calling_agent
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

# å¼•å…¥é…ç½®èˆ‡æ–‡æ¡ˆ
from app.config import settings
from app.prompts import SYSTEM_PROMPT

# å¼•å…¥ RAG åˆå§‹åŒ–å‡½å¼
from app.rag.retriever import init_rag

# å¼•å…¥æ‹†åˆ†å¾Œçš„å·¥å…· (è«‹ç¢ºä¿é€™äº›æª”æ¡ˆå·²å»ºç«‹)
from app.tools.ops import search_error_cards, search_litellm_logs
from app.tools.communication import send_email_to_engineer
from app.tools.security import verify_prompt_with_guardrails

def build_llm():
    """
    æ ¹æ“š app/config.py çš„è¨­å®šï¼Œå»ºç«‹å°æ‡‰çš„ LLM å¯¦é«”ã€‚
    """
    provider = settings.LLM_PROVIDER
    
    if provider == "azure":
        # æª¢æŸ¥å¿…è¦åƒæ•¸
        if not (settings.AZURE_OPENAI_ENDPOINT and settings.AZURE_OPENAI_API_KEY and settings.AZURE_OPENAI_DEPLOYMENT):
             raise RuntimeError("LLM_PROVIDER=azureï¼Œä½† AZURE_OPENAI_* ç›¸é—œè¨­å®šä¸å®Œæ•´ã€‚")
             
        return AzureChatOpenAI(
            azure_endpoint=settings.AZURE_OPENAI_ENDPOINT,
            api_key=settings.AZURE_OPENAI_API_KEY,
            api_version=settings.AZURE_OPENAI_API_VERSION,
            azure_deployment=settings.AZURE_OPENAI_DEPLOYMENT,
            timeout=settings.TIMEOUT_SECONDS,
            temperature=0.2,
            streaming=True
        )

    elif provider == "bedrock":
        return ChatBedrock(
        model_id=settings.BEDROCK_MODEL_ID,  # æˆ–è€…ç”¨ haiku / opus
        region_name=settings.AWS_REGION,  # æˆ–æ˜¯ä½ æ¨¡å‹é–‹é€šçš„å€åŸŸï¼Œå¦‚ us-west-2
        model_kwargs={
            "temperature": 0.2,
        }
    )

    else: # é è¨­ç‚º OpenAI
        if not settings.OPENAI_API_KEY:
            raise RuntimeError("LLM_PROVIDER=openaiï¼Œä½† OPENAI_API_KEY æœªè¨­å®šã€‚")

        return ChatOpenAI(
            api_key=settings.OPENAI_API_KEY,
            model=settings.OPENAI_MODEL,
            timeout=settings.TIMEOUT_SECONDS,
            temperature=0.2,
            streaming=True
        )

def build_agent_executor():
    """
    çµ„è£ LLMã€Tools èˆ‡ Promptï¼Œå»ºç«‹ Agent åŸ·è¡Œå™¨ã€‚
    """
    # 1. åˆå§‹åŒ– RAG (è¼‰å…¥ ChromaDB)
    # æ”¾åœ¨é€™è£¡çš„å¥½è™•æ˜¯ï¼šåªæœ‰åœ¨ Agent çœŸæ­£è¦è¢«å»ºç«‹æ™‚ï¼Œæ‰æœƒå»è®€å– Vector DBï¼ŒåŠ å¿« import é€Ÿåº¦
    init_rag() 

    # 2. å»ºç«‹ LLM
    llm = build_llm()

    # 3. æº–å‚™å·¥å…·æ¸…å–®
    # é€™è£¡å°‡å¾ä¸åŒæ¨¡çµ„ import é€²ä¾†çš„å·¥å…·çµ„åˆåœ¨ä¸€èµ·
    tools = [
        search_error_cards,           # æŸ¥æ‰‹å†Š (ops.py)
        search_litellm_logs,          # æŸ¥ Log (ops.py)
        send_email_to_engineer,       # å¯„ä¿¡ (communication.py)
        verify_prompt_with_guardrails # æŸ¥è­·æ¬„ (security.py)
    ]

    # 4. è¨­å®š Prompt Template
    # ä½¿ç”¨ ChatPromptTemplate è®“çµæ§‹æ›´æ¸…æ™°
    prompt = ChatPromptTemplate.from_messages([
        ("system", SYSTEM_PROMPT), 
        MessagesPlaceholder(variable_name="chat_history"),
        # ("human", "{input}"),
        MessagesPlaceholder(variable_name="user_message"),
        MessagesPlaceholder(variable_name="agent_scratchpad"),
    ])

    # 5. å»ºç«‹ Agent
    # create_tool_calling_agent æ˜¯ LangChain é‡å°æ”¯æ´ Function Calling æ¨¡å‹ (GPT/Claude) çš„æœ€ä½³å¯¦ä½œ
    agent = create_tool_calling_agent(llm, tools, prompt)

    # 6. å›å‚³åŸ·è¡Œå™¨
    return AgentExecutor(agent=agent, tools=tools, verbose=True)


class AgentSingleton:
    """
    å–®ä¾‹æ¨¡å¼ç®¡ç†å™¨ (Singleton Pattern)
    ç¢ºä¿æ•´å€‹æ‡‰ç”¨ç¨‹å¼ç”Ÿå‘½é€±æœŸä¸­ï¼ŒAgentExecutor åªæœƒè¢«åˆå§‹åŒ–ä¸€æ¬¡ã€‚
    é¿å…é‡è¤‡é€£ç·šè³‡æ–™åº«æˆ–é‡è¤‡è¼‰å…¥ RAG æ¨¡å‹ã€‚
    """
    _instance = None
    
    @classmethod
    def get_executor(cls):
        if cls._instance is None:
            print("ğŸ¤– åˆå§‹åŒ– Wuli Agent ...")
            cls._instance = build_agent_executor()
            print("âœ… Wuli Agent å°±ç·’ï¼")
        return cls._instance