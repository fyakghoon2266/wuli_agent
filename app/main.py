# app/main.py
import time
import json
import base64
import mimetypes
import os
from typing import List, Any, Dict

import gradio as gr
from langchain_core.messages import HumanMessage, AIMessage

# å¼•å…¥é‡æ§‹å¾Œçš„æ¨¡çµ„
from app.config import settings
from app.prompts import SYSTEM_PROMPT
from app.llm_factory import AgentSingleton
from app.ui.layout import create_demo
from app.utils.logging import save_chat_log

# å–å¾— Agent åŸ·è¡Œå™¨å¯¦é«”
agent_executor = AgentSingleton.get_executor()

# ===================== åœ–ç‰‡è™•ç†å·¥å…· =====================

def encode_image(image_path):
    """å°‡åœ–ç‰‡æª”æ¡ˆè½‰ç‚º Base64 å­—ä¸²"""
    if not image_path or not os.path.exists(image_path):
        return None, None
        
    # ç°¡å–®åˆ¤æ–· mime type
    mime_type, _ = mimetypes.guess_type(image_path)
    if not mime_type:
        mime_type = "image/jpeg"
        
    with open(image_path, "rb") as image_file:
        encoded_string = base64.b64encode(image_file.read()).decode('utf-8')
        
    return mime_type, encoded_string

def process_history_for_langchain(gradio_history: List[Any]) -> List[Any]:
    """
    ã€é—œéµä¿®å¾©ã€‘å°‡ Gradio çš„æ­·å²ç´€éŒ„æ¸…æ´—ç‚º LangChain/Bedrock å¯æ¥å—çš„æ ¼å¼
    è§£æ±º 'Input tag file found using type' éŒ¯èª¤
    """
    langchain_history = []
    
    if not gradio_history:
        return langchain_history

    # é‡å° Gradio 4.0+ çš„ dict æ ¼å¼æ­·å²ç´€éŒ„é€²è¡Œè¿­ä»£
    # æ ¼å¼é€šå¸¸æ˜¯: [{'role': 'user', 'content': ...}, {'role': 'assistant', 'content': ...}]
    if isinstance(gradio_history[0], dict):
        for msg in gradio_history:
            role = msg.get("role")
            content_raw = msg.get("content")
            
            # æº–å‚™è½‰æ›å¾Œçš„ content
            final_content = []
            
            # A. å¦‚æœ content æ˜¯å­—ä¸² (ç´”æ–‡å­—)
            if isinstance(content_raw, str):
                final_content = content_raw
            
            # B. å¦‚æœ content æ˜¯åˆ—è¡¨ (å¤šæ¨¡æ…‹: æ–‡å­— + åœ–ç‰‡/æª”æ¡ˆ)
            elif isinstance(content_raw, list):
                for item in content_raw:
                    # æƒ…æ³ 1: ç´”æ–‡å­—å€å¡Š
                    if isinstance(item, dict) and item.get("type") == "text":
                        final_content.append({"type": "text", "text": item.get("text")})
                    
                    # æƒ…æ³ 2: æª”æ¡ˆ/åœ–ç‰‡å€å¡Š (Gradio å­˜æˆ 'file' æˆ– 'image')
                    # ğŸ”¥ é‡é»ï¼šBedrock ä¸åƒ 'file'ï¼Œæˆ‘å€‘è¦è½‰æˆ 'image_url' æˆ–ç•¥é
                    elif isinstance(item, dict) and item.get("type") in ["file", "image"]:
                        file_path = item.get("url") or item.get("path") # Gradio ç‰ˆæœ¬ä¸åŒ key å¯èƒ½ä¸åŒ
                        
                        # å˜—è©¦è®€å–åœ–ç‰‡è½‰ base64
                        # æ³¨æ„ï¼šç‚ºäº†ç¯€çœ Token å’Œé¿å…å ±éŒ¯ï¼Œé€™è£¡æœ‰å…©å€‹ç­–ç•¥ï¼š
                        # ç­–ç•¥ 1 (å®Œæ•´): å†æ¬¡è½‰æª”å‚³çµ¦ LLM (æˆæœ¬é«˜ï¼Œä¸”å¦‚æœ temp æª”è¢«åˆªæœƒå ±éŒ¯)
                        # ç­–ç•¥ 2 (çœéŒ¢/ç©©å¥): æ­·å²åœ–ç‰‡åªç•™å€‹ "[åœ–ç‰‡]" æ¨™è¨˜ï¼Œåªè®“ LLM çœ‹æœ€æ–°ä¸Šå‚³çš„åœ–
                        
                        # é€™è£¡æ¡ç”¨ã€æ··åˆç­–ç•¥ã€‘ï¼šå¦‚æœæ˜¯ User çš„æœ€æ–°ä¸€å‰‡ï¼Œä¸€å®šè¦å‚³åœ–ï¼›
                        # ä½†å¦‚æœæ˜¯ã€Œæ­·å²ç´€éŒ„ã€ï¼Œç‚ºäº†é¿å… Bedrock å ±éŒ¯å’Œ Token çˆ†ç‚¸ï¼Œæˆ‘å€‘ç°¡åŒ–å®ƒã€‚
                        # ä½†å› ç‚ºä½ çš„éœ€æ±‚æ˜¯ "é€™è£é¢å¯«ä»€éº¼?" (Refer to previous image)ï¼Œ
                        # æˆ‘å€‘å˜—è©¦è®€å–çœ‹çœ‹ï¼Œè®€ä¸åˆ°å°±è®Šæ–‡å­—ã€‚
                        
                        m_type, b64_str = encode_image(file_path)
                        if b64_str:
                            final_content.append({
                                "type": "image_url",
                                "image_url": {"url": f"data:{m_type};base64,{b64_str}"}
                            })
                        else:
                            # è®€ä¸åˆ°æª”æ¡ˆ (å¯èƒ½è¢«æ¸…é™¤äº†)ï¼Œæ”¹ç”¨æ–‡å­—æ¨™è¨˜
                            final_content.append({"type": "text", "text": "[å·²ä¸Šå‚³ä¸€å¼µåœ–ç‰‡]"})

            # å»ºç«‹ Message ç‰©ä»¶
            if role == "user":
                langchain_history.append(HumanMessage(content=final_content))
            elif role == "assistant":
                langchain_history.append(AIMessage(content=final_content))
                
    return langchain_history

# ===================== é‚è¼¯è™•ç†å€ =====================

def respond(message: dict, history: List[Any]):
    """
    è™•ç†å°è©±é‚è¼¯ï¼šæ”¯æ´å¤šæ¨¡æ…‹è¼¸å…¥ï¼Œä¸¦ä¿®å¾© Bedrock æ ¼å¼éŒ¯èª¤èˆ‡ Unhashable Type éŒ¯èª¤
    """
    
    # 1. æ¸…æ´—æ­·å²ç´€éŒ„ (ä½¿ç”¨ process_history_for_langchain)
    chat_history = process_history_for_langchain(history)
    
    # 2. æº–å‚™æœ¬æ¬¡çš„ä½¿ç”¨è€…è¼¸å…¥ (User Message - çµ¦ LLM çœ‹çš„çœŸå¯¦å…§å®¹)
    user_content = []
    
    # ç”¨ä¾†çµ¦ AgentExecutor åš Log çš„ç´”æ–‡å­—æ‘˜è¦ (é¿å… unhashable error)
    raw_text_input = ""
    
    # åˆ¤æ–·æ˜¯å¦ç‚ºå¤šæ¨¡æ…‹è¼¸å…¥
    if isinstance(message, dict):
        text_input = message.get("text", "")
        files = message.get("files", [])
        
        # è¨˜éŒ„ç´”æ–‡å­—éƒ¨åˆ†
        raw_text_input = text_input

        # A. åŠ å…¥æ–‡å­—
        if text_input:
            user_content.append({"type": "text", "text": text_input})
        
        # B. åŠ å…¥åœ–ç‰‡
        for file_path in files:
            try:
                mime_type, base64_image = encode_image(file_path)
                if base64_image:
                    # ğŸ”¥ [Debug Log] ç¢ºèªåœ–ç‰‡è½‰ç¢¼æˆåŠŸ
                    print(f"ğŸ” [Debug] åœ–ç‰‡è½‰ç¢¼æˆåŠŸï¼æ ¼å¼: {mime_type}, é•·åº¦: {len(base64_image)}")
                    
                    user_content.append({
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:{mime_type};base64,{base64_image}"
                        }
                    })
                else:
                    print(f"âš ï¸ è­¦å‘Š: ç„¡æ³•è®€å–åœ–ç‰‡ {file_path}")
            except Exception as e:
                print(f"âŒ åœ–ç‰‡è®€å–å¤±æ•—: {e}")
    else:
        # ç´”æ–‡å­—ç›¸å®¹ (èˆŠç‰ˆ)
        user_content = message
        raw_text_input = str(message)

    # å¦‚æœåªæœ‰å‚³åœ–ç‰‡æ²’å‚³å­—ï¼Œçµ¦å€‹é è¨­æ–‡å­—ï¼Œé¿å… input ç‚ºç©º
    if not raw_text_input:
        raw_text_input = "[ä½¿ç”¨è€…ä¸Šå‚³äº†åœ–ç‰‡]"

    # ğŸ”¥ [é—œéµä¿®æ­£] å°‡ user_content åŒ…è£æˆ HumanMessage ç‰©ä»¶
    # é€™æ˜¯ç‚ºäº†é…åˆ Prompt Template ä¸­çš„ MessagesPlaceholder(variable_name="user_message")
    input_message = HumanMessage(content=user_content)

    # 3. æº–å‚™ Agent è¼¸å…¥
    input_data = {
        # ğŸŸ¢ [å…³é”® 1] "input": çµ¦ AgentExecutor å…§éƒ¨ç´€éŒ„ç”¨ (å¿…é ˆæ˜¯ Stringï¼Œé¿å… unhashable error)
        "input": raw_text_input,
        
        # ğŸŸ¢ [å…³é”® 2] "user_message": çœŸæ­£çµ¦ LLM çœ‹çš„å…§å®¹ (åŒ…å«åœ–ç‰‡ Payload)
        "user_message": [input_message],
        
        "chat_history": chat_history,
    }

    # ğŸ”¥ [Debug Log] ç¢ºèªé€å‡ºçš„çµæ§‹é¡å‹
    debug_input_summary = []
    if isinstance(user_content, list):
        for item in user_content:
            if isinstance(item, dict):
                debug_input_summary.append(item.get("type", "unknown"))
    print(f"ğŸš€ [Debug] æº–å‚™ç™¼é€çµ¦ Agent çš„è¼¸å…¥é¡å‹: {debug_input_summary}")

    # 4. åŸ·è¡Œèˆ‡å›å‚³
    try:
        for chunk in agent_executor.stream(input_data):
            
            # --- ç‹€æ³ A: å·¥å…·ä½¿ç”¨ç‹€æ…‹ ---
            if "actions" in chunk:
                for action in chunk["actions"]:
                    if action.tool == "search_error_cards":
                        yield "ğŸ¾ Wuli æ­£åœ¨ç¿»é–±ç¶­é‹æ‰‹å†Š..."
                    elif action.tool == "search_litellm_logs":
                         yield "ğŸ” Wuli æ­£åœ¨æ½›å…¥è³‡æ–™åº«æŸ¥ Log..."
                    elif action.tool == "verify_prompt_with_guardrails":
                         yield "ğŸ›¡ï¸ Wuli æ­£åœ¨é€²è¡Œå®‰å…¨æª¢æŸ¥..."
                    elif action.tool == "send_email_to_engineer":
                         yield "ğŸ“§ Wuli æ­£åœ¨å¯«ä¿¡çµ¦å·¥ç¨‹å¸«..."
            
            # --- ç‹€æ³ B: æœ€çµ‚å›ç­” ---
            if "output" in chunk:
                final_answer = chunk["output"]
                
                # Bedrock List -> Str è½‰æ›
                if isinstance(final_answer, list):
                    text_parts = []
                    for block in final_answer:
                        if isinstance(block, dict) and "text" in block:
                            text_parts.append(block["text"])
                        elif isinstance(block, str):
                            text_parts.append(block)
                    final_answer = "".join(text_parts)
                
                final_answer = str(final_answer)

                # ç©ºå­—ä¸²é˜²å‘†
                if not final_answer.strip():
                    final_answer = "âœ… åˆ†æå®Œæˆï¼(ä½† Wuli çœ‹å¾—å¤ªå…¥è¿·å¿˜è¨˜èªªè©±äº† ğŸ˜º)"

                yield "" # æ¸…é™¤ç‹€æ…‹

                # æ‰“å­—æ©Ÿæ•ˆæœ
                partial_message = ""
                for char in final_answer:
                    partial_message += char
                    yield partial_message
                    time.sleep(0.005)

                save_chat_log(message, final_answer)

    except Exception as e:
        error_msg = f"ğŸ˜¿ å—š... Wuli çš„çœ¼ç›å¥½åƒèŠ±äº†ï¼š{str(e)}"
        print(f"âŒ Error Details: {e}") # å°å‡ºè©³ç´°éŒ¯èª¤åˆ°å¾Œå°æ–¹ä¾¿é™¤éŒ¯
        save_chat_log(message, error_msg)
        yield error_msg
        
# ===================== Feedback è™•ç†å€ =====================

def clean_content(content):
    """è™•ç†å¤šæ¨¡æ…‹è³‡æ–™ï¼Œè½‰ç‚ºç´”æ–‡å­—"""
    if isinstance(content, str):
        return content
    if isinstance(content, list):
        text_parts = []
        for item in content:
            if isinstance(item, dict) and 'text' in item:
                text_parts.append(item['text'])
            elif isinstance(item, str):
                text_parts.append(item)
        return " ".join(text_parts)
    return str(content)

def on_feedback(x: gr.LikeData, history):
    """è™•ç†ä½¿ç”¨è€…æŒ‰è®š/å€’è®š"""
    index = x.index
    is_liked = x.liked 
    user_query_raw = "ç„¡æ³•è®€å–"
    bot_response_raw = "ç„¡æ³•è®€å–"

    try:
        # è§£æ History çµæ§‹ (é‡å°æ–°ç‰ˆ Gradio dict æ ¼å¼)
        if index < len(history):
             if isinstance(history[index], dict):
                 bot_response_raw = history[index].get('content', '')
                 if index > 0:
                     user_query_raw = history[index - 1].get('content', '')
             # é‡å°èˆŠç‰ˆ tuple æ ¼å¼
             elif isinstance(history[index], (list, tuple)):
                 # æ³¨æ„ï¼štuple æ ¼å¼é€šå¸¸ user/bot åœ¨åŒä¸€çµ„ï¼Œé‚è¼¯å¯èƒ½ä¸åŒï¼Œé€™è£¡é‡å° dict å„ªåŒ–
                 pass 

    except Exception as e:
        print(f"è§£æè³‡æ–™éŒ¯èª¤: {e}")

    # æ¸…ç†å…§å®¹
    user_query_clean = clean_content(user_query_raw)
    bot_response_clean = clean_content(bot_response_raw)

    # å¯«å…¥ JSONL
    feedback_data = {
        "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
        "user_query": user_query_clean,
        "bot_response": bot_response_clean,
        "is_positive": is_liked,
        "raw_index": index
    }
    
    try:
        with open("feedback_log/feedback_log.jsonl", "a", encoding="utf-8") as f:
            f.write(json.dumps(feedback_data, ensure_ascii=False) + "\n")
        
        status = "ğŸ‘" if is_liked else "ğŸ‘"
        print(f"å›é¥‹å·²å„²å­˜: {status} | User: {user_query_clean[:10]}...")
    except Exception as e:
        print(f"å¯«å…¥æª”æ¡ˆå¤±æ•—: {e}")





# ===================== ç¨‹å¼å…¥å£ =====================

if __name__ == "__main__":
    # ä½¿ç”¨ layout.py æä¾›çš„å·¥å» å‡½å¼å»ºç«‹ UI
    # ä¸¦æ³¨å…¥æˆ‘å€‘çš„é‚è¼¯å‡½å¼ (respond, on_feedback)
    demo = create_demo(respond_fn=respond, feedback_fn=on_feedback)
    
    # å•Ÿå‹•ä¼ºæœå™¨
    demo.launch(server_name="127.0.0.1", server_port=8002, root_path="/wuliagent")